{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Project Title: [Data Classificcation]\n",
    "___\n",
    "\n",
    "#### a. Introduction\n",
    "\n",
    "- **Objective:** Clearly state the goal of your project. What problem are you trying to solve?\n",
    "- **Background:** Provide context on why this problem is important or interesting. Mention any relevant research, datasets, or industry relevance.\n",
    "- **Scope:** Define the boundaries of your project. What will be included, and what will be out of scope?\n",
    "\n",
    "#### b. Project Overview\n",
    "\n",
    "- **Project Summary:** A brief overview of the project, including the main steps you will take to achieve the objective.\n",
    "- **Milestones:** Outline the key milestones or phases of the project. For example:\n",
    "  - Data Collection\n",
    "  - Data Preprocessing\n",
    "  - Model Selection\n",
    "  - Model Training and Evaluation\n",
    "  - Results and Conclusion\n",
    "\n",
    "\n",
    "#### c. About the Author\n",
    "\n",
    "- **Name:** [Ahmed Ferganey]\n",
    "- **Background:** Junior Data Scientist and Machine Learning Engineer with a strong foundation in embedded systems, industrial engineering, and supply chain management. Knowledgeable in statistical analysis, NLP, Computer Vision, and deep learning, with hands-on experience in Python, SQL, and Docker.\n",
    "- **Motivation:** Why are you interested in this project? What do you hope to learn or achieve?\n",
    "- **Contact:** [LinkedIn acc](https://www.linkedin.com/in/ahmed-ferganey/)\n",
    "\n",
    "\n",
    "\n",
    "#### d. Tools and Technologies\n",
    "\n",
    "- **Programming Languages:** List the programming languages you will use (e.g., Python).\n",
    "- **Libraries and Frameworks:** List the specific libraries and frameworks you will use (e.g., TensorFlow, scikit-learn).\n",
    "- **Software and Tools:** Mention any software or tools necessary for the project (e.g., Jupyter Notebook, Git).\n",
    "\n",
    "#### e. Dataset Description\n",
    "\n",
    "- **Dataset Name:** [Name of the Dataset]\n",
    "- **Source:** Where did you obtain the dataset? Include a link if possible.\n",
    "- **Description:** Briefly describe the dataset, including the number of features, the target variable, and any other important details.\n",
    "- **Data Preprocessing:** Outline any preprocessing steps you anticipate, such as data cleaning, normalization, or feature engineering.\n",
    "\n",
    "#### f. Methodology\n",
    "\n",
    "- **Model Selection:** Describe the types of models you are considering and why.\n",
    "- **Evaluation Metrics:** Define how you will evaluate your models' performance (e.g., accuracy, F1-score).\n",
    "- **Validation Strategy:** Explain how you will validate your models, such as cross-validation or a \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. importing libraries\n",
    "___\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import io\n",
    "import sys\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectPercentile , f_classif ,SelectKBest\n",
    "from sklearn.feature_selection import chi2 , f_classif \n",
    "import plotly.express as px\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis,QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. reading the raw data\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the main directory\n",
    "path_ = r'/media/ahmed-ferganey/AI4/01-Learning_AI/MyGitHub/Machine_Learning_Projects/CSV_Files/data_new'\n",
    "\n",
    "# Paths for saving files\n",
    "merged_output_path = r'/media/ahmed-ferganey/AI4/01-Learning_AI/MyGitHub/Machine_Learning_Projects/CSV_Files/data_new/merged_output.csv'\n",
    "headered_output_path = r'/media/ahmed-ferganey/AI4/01-Learning_AI/MyGitHub/Machine_Learning_Projects/CSV_Files/data_new/DataReading.csv'\n",
    "\n",
    "# Lists to store data and file details\n",
    "merged_data = []\n",
    "all_joint_positions_files = {}\n",
    "all_labels_files = {}\n",
    "deleted_files = []\n",
    "subfolder_number = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traverse the main directory\n",
    "for folder in tqdm(os.listdir(path_)):\n",
    "    subfolder_path = os.path.join(path_, folder)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(subfolder_path):\n",
    "        # Count and store the number of items in this subfolder\n",
    "        subfolder_number[folder] = len(os.listdir(subfolder_path))\n",
    "        \n",
    "        # Traverse each subdirectory in this subfolder\n",
    "        for subfolder in os.listdir(subfolder_path):\n",
    "            final_folder_path = os.path.join(subfolder_path, subfolder)\n",
    "            \n",
    "            # Check if it's a directory\n",
    "            if os.path.isdir(final_folder_path):\n",
    "                joint_positions_exists = False\n",
    "                labels_exists = False\n",
    "                joint_positions_file = None\n",
    "                labels_file = None\n",
    "                \n",
    "                for file in os.listdir(final_folder_path):\n",
    "                    full_file_path = os.path.join(final_folder_path, file)\n",
    "                    \n",
    "                    if file == 'Joint_Positions.csv':\n",
    "                        joint_positions_file = full_file_path\n",
    "                        joint_positions_exists = True\n",
    "                    elif file == 'Labels.csv':\n",
    "                        labels_file = full_file_path\n",
    "                        labels_exists = True\n",
    "                    else:\n",
    "                        # Delete any file that is not 'Joint_Positions.csv' or 'Labels.csv'\n",
    "                        os.remove(full_file_path)\n",
    "                        deleted_files.append(full_file_path)\n",
    "                        print(f\"Deleted: {full_file_path}\")\n",
    "                \n",
    "                # Print an error message if one of the files is missing\n",
    "                if not joint_positions_exists:\n",
    "                    print(f\"Error: The path '{final_folder_path}' does not include the file 'Joint_Positions.csv'\")\n",
    "                if not labels_exists:\n",
    "                    print(f\"Error: The path '{final_folder_path}' does not include the file 'Labels.csv'\")\n",
    "                \n",
    "                # Calculate rows and ratios if both files are present\n",
    "                if joint_positions_exists and labels_exists:\n",
    "                    try:\n",
    "                        joint_df = pd.read_csv(joint_positions_file, header=None)\n",
    "                        labels_df = pd.read_csv(labels_file, header=None)\n",
    "                        joint_rows = len(joint_df)\n",
    "                        labels_rows = len(labels_df)\n",
    "                        \n",
    "                        ratio = joint_rows / labels_rows if labels_rows > 0 else None\n",
    "                        all_joint_positions_files[joint_positions_file] = joint_rows\n",
    "                        all_labels_files[labels_file] = labels_rows\n",
    "                        \n",
    "                        print(f\"File Pair: {joint_positions_file} and {labels_file}\")\n",
    "                        print(f\"Joint_Positions.csv rows: {joint_rows}\")\n",
    "                        print(f\"Labels.csv rows: {labels_rows}\")\n",
    "                        print(f\"Ratio (Joint_Positions / Labels): {ratio:.2f}\" if ratio is not None else \"Error: Division by zero\")\n",
    "                        \n",
    "                        # Process each row in labels file\n",
    "                        for i in range(len(labels_df)):\n",
    "                            output_row = labels_df.iloc[i].values\n",
    "                            input_rows = joint_df.iloc[i * 25:(i + 1) * 25]\n",
    "                            input_data = input_rows.values.flatten()\n",
    "                            \n",
    "                            # Concatenate input data (75 columns) with output data\n",
    "                            merged_row = list(output_row) + list(input_data) + [folder, subfolder]\n",
    "                            merged_data.append(merged_row)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading files in directory '{final_folder_path}': {e}\")\n",
    "        \n",
    "        print('-----------------------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"Total Labels.csv files retained: {len(all_labels_files)}\")\n",
    "print(f\"Total Joint_Positions.csv files retained: {len(all_joint_positions_files)}\")\n",
    "print(f\"Total files deleted: {len(deleted_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame and save to CSV\n",
    "try:\n",
    "    # Define headers\n",
    "    header = ['OUTPUT']  # First column header\n",
    "\n",
    "    # Add Sample headers\n",
    "    for i in range(1, 26):  # For 25 samples\n",
    "        header.extend([f'Sample_{i}_X', f'Sample_{i}_Y', f'Sample_{i}_Z'])\n",
    "    \n",
    "    # Add new columns\n",
    "    header.extend(['Main_Folder', 'Sub_Folder'])\n",
    "    \n",
    "    # Create DataFrame and assign header\n",
    "    merged_df = pd.DataFrame(merged_data)\n",
    "    merged_df.columns = header\n",
    "    \n",
    "    # Save the DataFrame with header to a new CSV file\n",
    "    merged_df.to_csv(headered_output_path, index=False)\n",
    "    print(f\"Merged file with header saved to: {headered_output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving merged file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataReadingFrame = pd.read_csv(headered_output_path)\n",
    "DataReadingFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataReadingFrame['OUTPUT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataReadingFrame['OUTPUT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataReadingFrame['Main_Folder'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataReadingFrame['Sub_Folder'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. data analysis\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. data cleaning\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1 finding nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3 feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.4 feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. visualization\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. building the model\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. evaluation the model\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
